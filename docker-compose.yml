services:
    ollama:
        image: ollama/ollama:latest
        ports:
            - "11434:11434"
        environment:
            OLLAMA_HOST: 0.0.0.0
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: ["gpu"]

    workshop:
        build:
            context: .
        depends_on:
            - ollama
        command: ["bash"]
        working_dir: /workspace
        environment:
            OPENAI_API_KEY: "ollama"
            OPENAI_BASE_URL: "http://ollama:11434/v1"
            OLLAMA_HOST: "ollama:11434"
        volumes:
            - ./:/workspace
        stdin_open: true
        tty: true

volumes:
    ollama-data:
